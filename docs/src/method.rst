
Data preparation
================

Here we describe how to enhance the VCF file one gets from a usual variants caller
by adding useful annotation and moving the data into a relational database
to allow fast searching and filtering of variants within Varapp.

Input format
------------

The input data is a `multi-samples VCF <https://www.broadinstitute.org/gatk/guide/article?id=4150>`_
such as generated by GATK, and a pedigree (PED file) describing the familial relationships,
i.e. a 6 columns tab-delimited text file with a `.ped` extension::

    Family_ID  Individual_ID  Paternal_ID  Maternal_ID  Sex  Phenotype
    Fam1       A                                        1    1
    Fam1       B                                        2    1
    Fam1       C              A            B            1    2
    Fam1       D              A            B            2    2

Sex: 1=male, 2=female. Phenotype: 1=unaffected, 2=affected.
Paternal_ID and Maternal_ID are left blank if unknown; all other fields are mandatory.
The phenotype can be changed freely from the web interface.

If not provided, the PED file will be generated automatically, considering every sample
as coming from a different family (e.g. random cohort).

Typically, a multi-VCF contains one or a few families, or up to a few hundred individuals from a cohort.
For performance reasons, is is advised to rather split very large datasets when possible.
Varapp makes it easy to switch from one group to the other later on.

Annotation
----------

We need to add information to the VCF such as the
frequency in the population, impact, pathogenicity scores, etc. of each variant.
For that, we use Ensembl's `VEP <http://www.ensembl.org/info/docs/tools/vep/index.html>`_
and `Gemini <https://gemini.readthedocs.org/en/latest/>`_.

Varapp does not modify or add any more information to their output.
It will only keep track of which programs and databases versions
have been used to produce a dataset,
so that it is always possible to reproduce a result obtained with an older version.
*Note*: We use Gemini for annotation only; Varapp has its own query API for filtering.

The VCF gets first `decomposed and normalized with vt <http://genome.sph.umich.edu/wiki/Vt>`_, 
then `annotated with VEP 
<http://gemini.readthedocs.io/en/latest/content/functional_annotation.html#stepwise-installation-and-usage-of-vep>`_, 
then is `ran through Gemini <http://gemini.readthedocs.io/en/latest/content/quick_start.html>`_
to transform it into a relational database of annotated variants.

Until a later release, Varapp is sensible to the annotation it finds in the VCF.
Here is the command that we run to annotate with VEP::

    perl ${VEP_PATH}/variant_effect_predictor.pl -i <vcf> \
        --cache \
        --dir ${VEP_PATH}/.vepcache \
        --fasta $ref \
        --sift b \
        --polyphen b \
        --symbol \
        --numbers \
        --biotype \
        --total_length \
        --canonical --ccds \
        --vcf \
        --hgvs \
        --gene_phenotype \
        --uniprot \
        --force_overwrite \
        --domains --regulatory \
        --protein --tsl \
        --variant_class \
        --port 3337 \
        -o ${VEP_OUT}

And this is the custom annotation we add from the VCF INFO field into Gemini::

    gemini annotate -f <vcf> \
        -a extract \
        -c AF,BaseQRankSum,FS,MQRankSum,ReadPosRankSum,SOR \
        -t float,float,float,float,float,float \
        -e AF,BaseQRankSum,FS,MQRankSum,ReadPosRankSum,SOR \
        -o mean,mean,mean,mean,mean,mean \
        <gemini_db>

The complete pipeline we use can be found :doc:`here <annotate_vcf>`.


The annotation with VEP can take a few hours. However, it has to be done only once.

Variants databases
------------------

For each samples batch, the previous step produces a database (SQLite).

Varapp can interrogate as many of these variants databases as the user needs.
The user interface allows to change the working database in one click.
For performance reasons, we don't recommend generating databases containing more than 500K variants.

Loading the databases
---------------------

It is time to install the app. First follow the :doc:`./deployment` instructions.

Manually
........

At this point the app needs to be told where to look for Gemini databases.
This is done by setting `GEMINI_DB_PATH` to the location of your files in the config file
``settings.py`` of the backend.

Then you copy new Gemini databases into that directory, they will be detected by the application
and added to the list of available databases in the Admin panel, so that the administrator 
can attribute them to users.

Alternatively, you can fill the `variants_db` table of "users_db",
in a similar fashion to the "demo" data already present, or use it to add metadata.
Be careful though that the field 'name' must be unique.

Automated pipeline
..................

(In construction)

.. For convenience, we provide a pipeline running through all the steps described below.
   Drop your VCF and PED files inside the folder indicated by ``SOME_ENV_VARIABLE`` in `some_config_file`,
   and they get automatically loaded into Varapp when ready.

.. There is no need to use the pipeline if you don't want to: in the end, Varapp only cares about
   the Gemini databases it finds inside the folder indicated by ``SOME_OTHER_VARIABLE`` in
   `some_config_file`. Actually, any SQLite database with the same
   `schema <http://gemini.readthedocs.org/en/latest/content/database_schema.html>`_
   as Gemini produces can be used.


Start using the app
-------------------

As soon as the data is ready, there is no need to look at those files anymore.
Log in Varapp and start using the graphical interface.

